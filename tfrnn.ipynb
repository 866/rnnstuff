{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data...\n",
      "Number of words:\n",
      "\tin training set:11031\n",
      "\tin validation set:4728\n"
     ]
    }
   ],
   "source": [
    "logs_path = './rnn_words'\n",
    "writer = tf.summary.FileWriter(logs_path)\n",
    "train_split = .7\n",
    "\n",
    "# Text file containing words for training\n",
    "training_file = './dost.txt'#'belling_the_cat.txt'#\n",
    "\n",
    "def read_data(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.read().lower()\n",
    "    content = re.sub(r'[\\!\\.]', ' fullstop ', content)\n",
    "    content = re.findall(r'\\w+', content)\n",
    "    content = np.array(content, dtype=str)\n",
    "    content = np.reshape(content, [-1, ])\n",
    "    return content\n",
    "\n",
    "print(\"Loaded training data...\")\n",
    "data = read_data(training_file)\n",
    "train_cut = int(len(data) * train_split)\n",
    "train_data = data[:train_cut]\n",
    "valid_data = data[train_cut:]\n",
    "print(\"Number of words:\\n\\tin training set:{0}\\n\\tin validation set:{1}\".format(len(train_data), len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4300\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "dictionary, reverse_dictionary = build_dataset(data)\n",
    "vocab_size = len(dictionary)\n",
    "print(\"Vocabulary size: {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, data, batch_size, n):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.n = n\n",
    "        self.offset = random.randint(0, n+1)\n",
    "    def generate(self):\n",
    "        while True:\n",
    "            keys_in = np.ndarray((self.batch_size, self.n, 1), dtype=float)\n",
    "            onehot_out = np.zeros([self.batch_size, vocab_size], dtype=float)\n",
    "            for i in range(self.batch_size):\n",
    "                end_offset = self.n + 1\n",
    "                if self.offset > (len(self.data)-end_offset):\n",
    "                    self.offset = random.randint(0, self.n+1)\n",
    "                symbols = [ str(self.data[i]) for i in range(self.offset, self.offset+self.n) ]\n",
    "                symbols_in_keys = [ [dictionary[s]] for s in symbols ]\n",
    "                keys_in[i, :, :] = np.reshape(np.array(symbols_in_keys), [self.n, 1])\n",
    "                onehot_out[i, dictionary[str(self.data[self.offset+self.n])]] = 1     \n",
    "                self.offset += (self.n+1)\n",
    "            yield keys_in, onehot_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size=128\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "display_step = 1000\n",
    "validation_step = 5000\n",
    "save_after = 5000\n",
    "embedding_size = 10\n",
    "n_input = 3\n",
    "\n",
    "train_batch = BatchGenerator(train_data, batch_size, n_input).generate()\n",
    "valid_batch = BatchGenerator(valid_data, batch_size, n_input).generate()\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 1024\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # RNN output node weights and biases\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "    }\n",
    "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "    def RNN(x, weights, biases, reuse=False):\n",
    "\n",
    "        # reshape to [1, n_input]\n",
    "        x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "        # Generate a n_input-element sequence of inputs\n",
    "        # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "        x = tf.split(x,n_input,1)\n",
    "\n",
    "        # 2-layer LSTM, each layer has n_hidden units.\n",
    "        # Average Accuracy= 95.20% at 50k iter\n",
    "        # rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "        # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "        # Average Accuracy= 90.60% 50k iter\n",
    "        # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "        rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "        # generate prediction\n",
    "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "        # there are n_input outputs but\n",
    "        # we only want the last output\n",
    "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "    pred = RNN(x, weights, biases)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    # Model evaluation\n",
    "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    #global_step = tf.Variable(0)\n",
    "    #learning_rate = tf.train.exponential_decay(\n",
    "    #    learning_rate, global_step, training_iters, 0.01, staircase=True)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    #gradients, v = zip(*optimizer.compute_gradients(cost))\n",
    "    #gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "    #optimizer = optimizer.apply_gradients(zip(gradients, v), global_step=global_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step averagely takes: 0.020588513612747193s\n",
      "Time to end this nightmare: 16.81min\n",
      "Iter= 1000, Average Loss= 7.843556, Average Accuracy= 5.57%\n",
      "['ли', 'надо', 'мною'] - true:[не] vs pred:[и]\n",
      "============================================================\n",
      "Step averagely takes: 0.02050762104988098s\n",
      "Time to end this nightmare: 16.41min\n",
      "Iter= 2000, Average Loss= 5.679133, Average Accuracy= 7.92%\n",
      "['в', 'дом', 'войти'] - true:[не] vs pred:[fullstop]\n",
      "============================================================\n",
      "Step averagely takes: 0.0205819833278656s\n",
      "Time to end this nightmare: 16.12min\n",
      "Iter= 3000, Average Loss= 4.681732, Average Accuracy= 15.23%\n",
      "['родная', 'моя', 'fullstop'] - true:[что] vs pred:[начну]\n",
      "============================================================\n",
      "Step averagely takes: 0.02054229426383972s\n",
      "Time to end this nightmare: 15.75min\n",
      "Iter= 4000, Average Loss= 4.280234, Average Accuracy= 20.15%\n",
      "['то', 'и', 'объявила'] - true:[наконец] vs pred:[я]\n",
      "============================================================\n",
      "Step averagely takes: 0.020569063425064087s\n",
      "Time to end this nightmare: 15.43min\n",
      "Iter= 5000, Average Loss= 3.722227, Average Accuracy= 28.20%\n",
      "['я', 'всё', 'для'] - true:[удобства] vs pred:[удобства]\n",
      "============================================================\n",
      "Model saved in file: ./model.ckpt\n",
      "Validation accuracy: 4.69% loss: 11.474390029907227\n",
      "Step averagely takes: 0.021473889112472534s\n",
      "Time to end this nightmare: 15.75min\n",
      "Iter= 6000, Average Loss= 3.356592, Average Accuracy= 33.93%\n",
      "['писано', 'в', 'разные'] - true:[сроки] vs pred:[сроки]\n",
      "============================================================\n",
      "Step averagely takes: 0.020588733196258546s\n",
      "Time to end this nightmare: 14.76min\n",
      "Iter= 7000, Average Loss= 3.128373, Average Accuracy= 37.66%\n",
      "['и', 'покровский', 'вошел'] - true:[в] vs pred:[теперь]\n",
      "============================================================\n",
      "Step averagely takes: 0.020548259019851686s\n",
      "Time to end this nightmare: 14.38min\n",
      "Iter= 8000, Average Loss= 2.832356, Average Accuracy= 42.38%\n",
      "['всего', 'двое', 'тереза'] - true:[да] vs pred:[всё]\n",
      "============================================================\n",
      "Step averagely takes: 0.020568487644195558s\n",
      "Time to end this nightmare: 14.06min\n",
      "Iter= 9000, Average Loss= 2.479011, Average Accuracy= 48.08%\n",
      "['всё', 'пошло', 'вверх'] - true:[дном] vs pred:[и]\n",
      "============================================================\n",
      "Step averagely takes: 0.02072610902786255s\n",
      "Time to end this nightmare: 13.82min\n",
      "Iter= 10000, Average Loss= 2.510941, Average Accuracy= 48.22%\n",
      "['то', 'была', 'знаете'] - true:[маленькая] vs pred:[маленькая]\n",
      "============================================================\n",
      "Model saved in file: ./model.ckpt\n",
      "Validation accuracy: 1.56% loss: 15.280984878540039\n",
      "Step averagely takes: 0.02138096022605896s\n",
      "Time to end this nightmare: 13.90min\n",
      "Iter= 11000, Average Loss= 2.416976, Average Accuracy= 48.98%\n",
      "['fullstop', 'fullstop', 'fullstop'] - true:[fullstop] vs pred:[fullstop]\n",
      "============================================================\n",
      "Step averagely takes: 0.02052798366546631s\n",
      "Time to end this nightmare: 13.00min\n",
      "Iter= 12000, Average Loss= 2.066881, Average Accuracy= 55.26%\n",
      "['много', 'ль', 'останется'] - true:[вот] vs pred:[fullstop]\n",
      "============================================================\n",
      "Step averagely takes: 0.020536996841430663s\n",
      "Time to end this nightmare: 12.66min\n",
      "Iter= 13000, Average Loss= 2.080457, Average Accuracy= 55.04%\n",
      "['и', 'ничего', 'fullstop'] - true:[и] vs pred:[и]\n",
      "============================================================\n",
      "Step averagely takes: 0.020537792444229125s\n",
      "Time to end this nightmare: 12.32min\n",
      "Iter= 14000, Average Loss= 1.776888, Average Accuracy= 60.83%\n",
      "['ведь', 'вам', 'уже'] - true:[пятнадцать] vs pred:[пятнадцать]\n",
      "============================================================\n",
      "Step averagely takes: 0.020571749210357666s\n",
      "Time to end this nightmare: 12.00min\n",
      "Iter= 15000, Average Loss= 1.995521, Average Accuracy= 56.99%\n",
      "['хуже', 'моего', 'fullstop'] - true:[жалкий] vs pred:[весьма]\n",
      "============================================================\n",
      "Model saved in file: ./model.ckpt\n",
      "Validation accuracy: 3.12% loss: 15.51976203918457\n",
      "Step averagely takes: 0.021490196466445923s\n",
      "Time to end this nightmare: 12.18min\n",
      "Iter= 16000, Average Loss= 1.914721, Average Accuracy= 57.81%\n",
      "['оставил', 'его', 'своим'] - true:[покровительством] vs pred:[покровительством]\n",
      "============================================================\n",
      "Step averagely takes: 0.02052307415008545s\n",
      "Time to end this nightmare: 11.29min\n",
      "Iter= 17000, Average Loss= 1.801681, Average Accuracy= 60.13%\n",
      "['круглому', 'столу', 'выпьем'] - true:[чайку] vs pred:[сердца]\n",
      "============================================================\n",
      "Step averagely takes: 0.020537396907806395s\n",
      "Time to end this nightmare: 10.95min\n",
      "Iter= 18000, Average Loss= 1.666781, Average Accuracy= 62.25%\n",
      "['бывало', 'гости', 'ездили'] - true:[и] vs pred:[fullstop]\n",
      "============================================================\n",
      "Step averagely takes: 0.02055989408493042s\n",
      "Time to end this nightmare: 10.62min\n",
      "Iter= 19000, Average Loss= 1.637466, Average Accuracy= 62.65%\n",
      "['их', 'скушайте', 'на'] - true:[здоровье] vs pred:[здоровье]\n",
      "============================================================\n",
      "Step averagely takes: 0.020538622856140137s\n",
      "Time to end this nightmare: 10.27min\n",
      "Iter= 20000, Average Loss= 1.639502, Average Accuracy= 62.67%\n",
      "['мне', 'привыкать', 'к'] - true:[новой] vs pred:[новой]\n",
      "============================================================\n",
      "Model saved in file: ./model.ckpt\n",
      "Validation accuracy: 2.34% loss: 18.549942016601562\n",
      "Step averagely takes: 0.02158186626434326s\n",
      "Time to end this nightmare: 10.43min\n",
      "Iter= 21000, Average Loss= 1.604299, Average Accuracy= 63.06%\n",
      "['целых', 'три', 'дня'] - true:[я] vs pred:[я]\n",
      "============================================================\n",
      "Step averagely takes: 0.02058351469039917s\n",
      "Time to end this nightmare: 9.61min\n",
      "Iter= 22000, Average Loss= 1.517841, Average Accuracy= 64.73%\n",
      "['уж', 'истинно', 'не'] - true:[могу] vs pred:[могу]\n",
      "============================================================\n",
      "Step averagely takes: 0.020552351713180542s\n",
      "Time to end this nightmare: 9.25min\n",
      "Iter= 23000, Average Loss= 1.539229, Average Accuracy= 63.99%\n",
      "['молодой', 'покровский', 'похож'] - true:[как] vs pred:[как]\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "    tf.global_variables_initializer().run()\n",
    "    step = 0\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    writer.add_graph(session.graph)\n",
    "    time_tick = time.time()\n",
    "    while step < training_iters:\n",
    "        # Generate a minibatch. Add some randomness on selection process.\n",
    "        symbols_in_keys, symbols_out_onehot = next(train_batch)\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step+1) % display_step == 0:\n",
    "            iter_takes = (time.time() - time_tick) / display_step\n",
    "            print(\"Step averagely takes: {0}s\\nTime to end this nightmare: {1:0.2f}min\".format(iter_takes, \n",
    "                                                                                      (training_iters-step)*\n",
    "                                                                                             iter_takes/60))\n",
    "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            for j in range(1):\n",
    "                symbols_in = [reverse_dictionary[idx] for idx in symbols_in_keys[j, :, 0]]\n",
    "                symbols_out = reverse_dictionary[np.argmax(symbols_out_onehot[j, :])]\n",
    "                symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval()[j])]\n",
    "                print(\"%s - true:[%s] vs pred:[%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "            time_tick = time.time()\n",
    "            print(\"=\"*60)\n",
    "        if (step+1) % save_after == 0:\n",
    "            save_path = saver.save(session, \"./model.ckpt\")\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "        if (step+1) % validation_step == 0:\n",
    "            valid_samples = next(valid_batch)\n",
    "            acc, loss = session.run([accuracy, cost], \\\n",
    "                                                feed_dict={x: valid_samples[0], y: valid_samples[1]})\n",
    "            print(\"Validation accuracy: {0:0.2f}% loss: {1}\".format(acc*100, loss))\n",
    "        step += 1\n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Run on command line.\")\n",
    "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "    print(\"Point your web browser to: http://localhost:6006/\")\n",
    "    while True:\n",
    "        prompt = \"%s words: \" % n_input\n",
    "        sentence = input(prompt)\n",
    "        sentence = sentence.strip()\n",
    "        words = sentence.split(' ')\n",
    "        if len(words) != n_input:\n",
    "            continue\n",
    "        try:\n",
    "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "            for i in range(64):\n",
    "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "                onehot_pred = session.run(pred, feed_dict={x: keys})\n",
    "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval()[0])\n",
    "                sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
    "                symbols_in_keys = symbols_in_keys[1:]\n",
    "                symbols_in_keys.append(onehot_pred_index)\n",
    "            print(sentence)\n",
    "        except Exception as e:\n",
    "            print(\"Word not in dictionary\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
